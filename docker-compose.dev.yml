services:
  # NATS Message Bus
  nats:
    image: nats:2.10-alpine
    container_name: nats
    ports:
      - "4222:4222"
      - "8222:8222"
    command: ["nats-server", "-js", "-m", "8222"]
    networks:
      - loqa-network
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 4222"]
      interval: 10s
      timeout: 5s
      retries: 3

  # Ollama LLM Service
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    networks:
      - loqa-network
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 30s
      timeout: 10s
      retries: 3
    # Pull model on startup
    entrypoint: ["/bin/sh", "-c"]
    command: >
      "ollama serve &
       sleep 10 &&
       ollama pull llama3.2:3b &&
       wait"

  # STT Service
  stt:
    image: fedirz/faster-whisper-server:latest-cpu
    container_name: stt
    ports:
      - "8000:8000"
    volumes:
      - stt-cache:/app/cache
    environment:
      - WHISPER_MODEL=tiny
    networks:
      - loqa-network
    healthcheck:
      test: ["CMD", "python3", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # TTS Service (CPU version for development)
  tts:
    image: ghcr.io/remsky/kokoro-fastapi-cpu:latest
    container_name: tts
    ports:
      - "8880:8880"
    volumes:
      - tts-cache:/app/cache
    networks:
      - loqa-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8880/v1/audio/voices"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 45s

  # Loqa Hub - Central orchestrator
  hub:
    build:
      context: ..
      dockerfile: loqa-hub/Dockerfile
    container_name: hub
    ports:
      - "3000:3000"
      - "50051:50051"
    environment:
      - STT_URL=http://stt:8000
      - TTS_URL=http://tts:8880/v1
      - TTS_VOICE=af_bella
      - TTS_SPEED=1.0
      - TTS_FORMAT=mp3
      - TTS_NORMALIZE=true
      - TTS_MAX_CONCURRENT=5  # Lower for dev
      - TTS_TIMEOUT=10s
      - TTS_FALLBACK_ENABLED=true
      - OLLAMA_URL=http://ollama:11434
      - OLLAMA_MODEL=llama3.2:3b
      - NATS_URL=nats://nats:4222
      - NATS_SUBJECT=loqa.commands
      - LOQA_HOST=0.0.0.0
      - LOQA_PORT=3000
      - LOQA_GRPC_PORT=50051
      - LOG_LEVEL=info
      - LOG_FORMAT=json
    depends_on:
      nats:
        condition: service_healthy
      ollama:
        condition: service_started  # Start container but don't wait for model readiness - hub handles that
      stt:
        condition: service_healthy
      tts:
        condition: service_healthy
    volumes:
      - hub-data:/app/data
    networks:
      - loqa-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Commander Timeline UI
  commander:
    build:
      context: ../loqa-commander
      dockerfile: Dockerfile
    container_name: commander
    ports:
      - "5173:80"
    environment:
      - VITE_HUB_API_URL=http://localhost:3000
      - HUB_SERVICE_NAME=hub
    depends_on:
      hub:
        condition: service_healthy
    networks:
      - loqa-network

  # Test Relay (optional - for testing)
  test-relay:
    build:
      context: ..
      dockerfile: loqa-relay/Dockerfile
    container_name: test-relay
    environment:
      - HUB_ADDRESS=hub:50051
      - RELAY_ID=docker-test-relay
      - WAKE_WORD_THRESHOLD=0.7
    depends_on:
      hub:
        condition: service_healthy
    networks:
      - loqa-network
    # Only run if you have audio devices available
    profiles:
      - testing

volumes:
  ollama-data:
    driver: local
  hub-data:
    driver: local
  stt-cache:
    driver: local
  tts-cache:
    driver: local

networks:
  loqa-network:
    driver: bridge